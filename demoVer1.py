from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings
import json
import streamlit as st 
from openai import OpenAI 
import os 
from dotenv import load_dotenv
from neo4j import GraphDatabase
from prompts_for_demo1 import *
load_dotenv()

# Set page config
st.set_page_config(
    page_title="ì„œë¹„ìŠ¤ ì¶”ì²œ ì‹œìŠ¤í…œ",
    page_icon="ğŸ¯",
    layout="wide"
)

# Apply custom CSS
st.markdown("""
    <style>
    .stApp {
        max-width: 1200px;
        margin: 0 auto;
    }
    .big-font {
        font-size:30px !important;
        font-weight: bold;
    }
    </style>
    """, unsafe_allow_html=True)

with st.spinner('ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•˜ëŠ” ì¤‘...'):
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    URI = os.getenv("NEO4J_URI")
    AUTH = (os.getenv("NEO4J_USERNAME"), os.getenv("NEO4J_PASSWORD"))
    driver = GraphDatabase.driver(URI, auth=AUTH)
    driver.verify_connectivity()

st.markdown('<p class="big-font">ì„œë¹„ìŠ¤ ì¶”ì²œ ì‹œìŠ¤í…œ ğŸ¯</p>', unsafe_allow_html=True)
st.markdown("---")

embeddings = OpenAIEmbeddings(model='text-embedding-3-large', api_key=os.getenv('OPENAI_API_KEY'))

db_service_description = Chroma(persist_directory='./database/exp19_vector_db_service_description', embedding_function=embeddings)
db_target_summary = Chroma(persist_directory='./database/exp19_vector_db_target_summary', embedding_function=embeddings)

# Load data with progress bar
with st.spinner('ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...'):
    with open('./database/exp17_db_compiling_with_age_restriction.json', 'r', encoding='utf-8') as f:
        db = json.load(f)

    with open('./database/exp11_clusters.json', 'r', encoding='utf-8') as f:
        clusters = json.load(f)

# Initialize session states
if "neo4j_data" not in st.session_state:
    st.session_state["neo4j_data"] = []
if "clusters" not in st.session_state:
    st.session_state["clusters"] = clusters
if "messages" not in st.session_state:
    st.session_state["messages"] = []
if "db" not in st.session_state:
    st.session_state["db"] = db
if "filtered_db" not in st.session_state:
    st.session_state["filtered_db"] = []
if "mapped_cluster" not in st.session_state:
    st.session_state["mapped_cluster"] = None
if 'step' not in st.session_state:
    st.session_state['step'] = 1
if 'age' not in st.session_state:
    st.session_state['age'] = None

# Create two columns for expanders
col1, col2 = st.columns(2)
with col1:
    with st.expander("ì„œë¹„ìŠ¤ í´ëŸ¬ìŠ¤í„° ì •ë³´ ğŸ“Š"):
        st.json(st.session_state["clusters"])
with col2:
    with st.expander("ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ ğŸ’¾"):
        st.json(st.session_state["db"])

# Display chat history in a container
with st.container():
    for message in st.session_state.messages:
        with st.chat_message(message["role"], avatar="ğŸ§‘â€ğŸ’»" if message["role"] == "user" else "ğŸ¤–"):
            st.markdown(message["content"])

# Display Neo4j data in a clean format
if st.session_state['neo4j_data']:
    with st.expander("Neo4j ë°ì´í„° ğŸ”"):
        st.json(st.session_state['neo4j_data'])

# Step 1: Service Query
if st.session_state['step'] == 1:
    st.info("ğŸ‘‹ ì›í•˜ì‹œëŠ” ì„œë¹„ìŠ¤ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”!")
    user_query = st.chat_input("ì°¾ê³ ì í•˜ëŠ” ì„œë¹„ìŠ¤ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”. [ex. ì£¼íƒ ì§€ì› ì„œë¹„ìŠ¤, ê±´ê°• ì§€ì› ì„œë¹„ìŠ¤, ì†Œë“ ì§€ì› ì„œë¹„ìŠ¤ ë“±]")

    if user_query:
        st.session_state.messages.append({"role": "user", "content": user_query})
        with st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»"):
            st.markdown(user_query)
        
        with st.spinner('ì„œë¹„ìŠ¤ë¥¼ ë¶„ì„í•˜ëŠ” ì¤‘...'):
            mapped_cluster = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT_TO_MAP_QUERY_TO_CLUSTER.format(clusters=st.session_state["clusters"])},
                    {"role": "user", "content": user_query}
                ],
                temperature=0.0,
                response_format={"type": "json_object"}
            )
            st.session_state.mapped_cluster = json.loads(mapped_cluster.choices[0].message.content)
            
        with st.chat_message("assistant", avatar="ğŸ¤–"):
            st.success("ì„œë¹„ìŠ¤ ë§¤í•‘ ì™„ë£Œ!")
            st.json(st.session_state.mapped_cluster)
            
        st.session_state.messages.append({"role": "assistant", "content": st.session_state.mapped_cluster})
        
        with st.spinner('ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ì¤‘...'):
            cluster_id = st.session_state.mapped_cluster['cluster_id']
            filtered_db = [service for service in st.session_state["db"] if service["cluster_id"] == cluster_id]
            
            with driver.session() as session:
                query = """
                MATCH (e: Event)-[:BELONGS_TO]->(c: Cluster {cluster_id: $cluster_id})
                return e as event
                """
                result = session.run(query, cluster_id=cluster_id)
                for record in result:
                    with st.expander("ê´€ë ¨ ì´ë²¤íŠ¸ ì •ë³´"):
                        st.json(record.get('event'))
                    st.session_state['neo4j_data'].append(record.get('event'))
                    
        st.session_state['db'] = filtered_db
        st.session_state['step'] += 1
        st.rerun()

# Step 2: Age Input
if st.session_state['step'] == 2:
    st.success(f"ğŸ¯ ê²€ìƒ‰ëœ ì„œë¹„ìŠ¤ ìˆ˜: {len(st.session_state['db'])}")
    st.info("ğŸ‘¤ ë‚˜ì´ ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
    user_query = st.chat_input('ë³¸ì¸ì˜ ë‚˜ì´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”. (ì˜ˆ: ë§Œ 20ì„¸ë¼ë©´ 20 ì…ë ¥)')
    
    if user_query:
        try:
            st.session_state.messages.append({"role": "user", "content": user_query})
            with st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»"):
                st.markdown(user_query)
                
            st.session_state['age'] = int(user_query)
            
            VALIDATOR_PROMPT_TO_FILTER_SERVICES_BY_AGE_RESTRICTION = """
            You are a helpful assistant that can help users find the services they need. As an input, you will be provided (1) User's current age, (2) Age restriction of the service. Your task is to check if the user's age satisfies the age restriction of the service. If it does, you should return "VALID". Otherwise, you should return "INVALID". Answer only with "VALID" or "INVALID".
            """.strip()
            
            progress_text = 'ë‚˜ì´ ì œí•œ í™•ì¸ ì¤‘...'
            with st.spinner(progress_text):
                for service in st.session_state['db']:
                    age_restriction = json.dumps(service['age_restriction'])
                    validator = client.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=[{"role": "system", "content": VALIDATOR_PROMPT_TO_FILTER_SERVICES_BY_AGE_RESTRICTION}, {"role": "user", "content": f"User's current age: {st.session_state['age']}, Age restriction of the service: {age_restriction}"}],
                        temperature=0.0,
                    )
                    if validator.choices[0].message.content == "VALID":
                        st.session_state['filtered_db'].append(service)
                        
            st.session_state['db'] = st.session_state['filtered_db']
            st.session_state['step'] += 1
            st.rerun()
            
        except ValueError:
            st.error("âš ï¸ ì˜¬ë°”ë¥¸ ë‚˜ì´ë¥¼ ìˆ«ìë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”!")

# Step 3: Display Results
if st.session_state['step'] == 3:
    st.success(f"âœ¨ ì¡°ê±´ì— ë§ëŠ” ì„œë¹„ìŠ¤ ìˆ˜: {len(st.session_state['db'])}")
    
    user_query = st.chat_input("ì„œë¹„ìŠ¤ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ììœ ë¡­ê²Œ ë¬¼ì–´ë³´ì„¸ìš”!")
    
    if user_query:
        st.session_state.messages.append({"role": "user", "content": user_query})
        with st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»"):
            st.markdown(user_query)
            
        with st.spinner('ë‹µë³€ ìƒì„± ì¤‘...'):
            # Determine which vector DB to use based on query
            query_category = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are tasked with mapping the user's query to either the [SERVICE_DESCRIPTION] or [TARGET_SUMMARY] vector database. If the user's query is related to the service description, return 'SERVICE_DESCRIPTION'. If the user's query is related to the target summary, return 'TARGET_SUMMARY'. If the user's query is not related to either, just return 'SERVICE_DESCRIPTION'."},
                    {"role": "user", "content": user_query}
                ]
            )
            query_category = query_category.choices[0].message.content
            if query_category == "SERVICE_DESCRIPTION":
                db = db_service_description
                docs = db.similarity_search(user_query, k=20)
            elif query_category == "TARGET_SUMMARY":
                db = db_target_summary
                docs = db.similarity_search(user_query, k=20)
            final_docs = []
            for doc in docs:
                metadata = json.loads(doc.metadata['original_data'])
                if metadata['cluster_id'] == st.session_state['mapped_cluster']['cluster_id']:
                    final_docs.append(doc)
                    with st.expander(f"ğŸ“Œ {metadata['service_title']}"):
                        st.markdown("### ì„œë¹„ìŠ¤ ì„¤ëª…")
                        st.write(metadata['service_description'])
                        
                        st.markdown("### ì§€ì› ëŒ€ìƒ")
                        st.write(metadata['summarized_target_content'])
                        
                        st.markdown("### ì§€ì› ë‚´ìš©")
                        st.write(metadata['support_content'])
                        
                        st.markdown("### ì‹ ì²­ ë°©ë²•")
                        st.write(metadata['apply_content'])
                        
                        st.markdown("### ë¬¸ì˜ì²˜")
                        st.write(metadata['contact_content'])
            st.write(f"ë‹¹ì‹ ê»˜ ë”± ë§ëŠ” ì„œë¹„ìŠ¤ë¥¼ {len(final_docs)}ê°œ ì°¾ì•˜ìŠµë‹ˆë‹¤.")